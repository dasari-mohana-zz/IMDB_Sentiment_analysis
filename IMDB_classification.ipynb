{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPac+r2FsYMNKTSVkee2muV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dasari-mohana/IMDB_Sentiment_analysis/blob/main/IMDB_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_lUGGIVHYIU"
      },
      "source": [
        "# IMDB dataset\n",
        "\n",
        "## Description:\n",
        "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. Provided a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided. See the README file contained in the release for more details.\n",
        "\n",
        "## Data Source\n",
        "Keras provides access to the IMDB dataset built-in. The imdb.load_data() function allows you to load the dataset in a format that is ready for use in neural network and deep learning models.\n",
        "\n",
        "The words have been replaced by integers that indicate the ordered frequency of each word in the dataset. The sentences in each review are therefore comprised of a sequence of integers.\n",
        "\n",
        "## Objective:\n",
        "\n",
        "To predict determine whether a given movie review has a positive or negative sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJdZP4ZmEUwV"
      },
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Flatten\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "np.random.seed(7)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAiYRWu2FmWl"
      },
      "source": [
        "# Importing dataset\n",
        "# Keras provides access to the IMDB dataset built-in. The imdb.load_data() function allows you to load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8Dj749uGR_c"
      },
      "source": [
        "We will also limit the total number of words that we are interested in modeling to the 5000 most frequent words, and zero out the rest. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etvggTp4H655"
      },
      "source": [
        "# load the dataset but only keep the top n words, zero the rest\n",
        "\n",
        "top_words = 5000\n",
        "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao3nIet_Gc5H"
      },
      "source": [
        "The sequence length (no.of words) in each review varies, so we will constrain each review to be 500 words, truncating long reviews and pad the shorter reviews with zero values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aScymYbsId1P"
      },
      "source": [
        "# Truncate and pad input sequences\n",
        "\n",
        "max_review_length = 500\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test,maxlen=max_review_length)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSMRA-5AJONo",
        "outputId": "2ccb604f-d483-4054-fea6-c442d8051e2c"
      },
      "source": [
        "# Create the model\n",
        "\n",
        "embedding_vector_length = 32\n",
        "\n",
        "# Buliding a sequential model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words, output_dim=embedding_vector_length, input_length=max_review_length))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                16600     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 176,651\n",
            "Trainable params: 176,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XYI_0kuLMOU",
        "outputId": "678fcf44-6b5d-4ac6-8736-eb1e28b53e38"
      },
      "source": [
        "# Compiling the model with metric as accuracy and Adam optimizer\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train, batch_size=64, epochs=3,validation_data=(X_test,y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 161s 405ms/step - loss: 0.4467 - accuracy: 0.7923 - val_loss: 0.3257 - val_accuracy: 0.8641\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 160s 408ms/step - loss: 0.2782 - accuracy: 0.8897 - val_loss: 0.2926 - val_accuracy: 0.8776\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 159s 406ms/step - loss: 0.2280 - accuracy: 0.9117 - val_loss: 0.2992 - val_accuracy: 0.8780\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f112fb75a50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKGxXB_zL_h4",
        "outputId": "be8cb354-cbf0-405e-a8ef-d03c49278e63"
      },
      "source": [
        "# Performance of the model\n",
        "\n",
        "scores = model.evaluate(X_test,y_test, verbose=0)\n",
        "print('Model accuracy : %.2f%%' %(scores[1]*100))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy : 87.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUYNXkcdO4H9"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.datasets import imdb\n",
        "np.random.seed(7)\n",
        "\n",
        "top_words = 5000\n",
        "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# Truncate and padding sequence\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test,maxlen=max_review_length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ul7o9fLPki0",
        "outputId": "e4b381d1-af10-4ebd-9d11-2d68193e15c2"
      },
      "source": [
        "# Create the model\n",
        "embedding_vector_length = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words, output_dim=embedding_vector_length, input_length=max_review_length))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(units=80))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 500, 32)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               53200     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYGuebszS7kO",
        "outputId": "76c80df7-4b6e-4fce-d014-ac722cd704b8"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics =['accuracy'])\n",
        "model.fit(X_train,y_train,batch_size=64,epochs=4,validation_data=(X_test,y_test),verbose=0)\n",
        "\n",
        "# model performance\n",
        "scores = model.evaluate(X_test,y_test, verbose=0)\n",
        "print('Model accuaracy %.2f%%' %(scores[1]*100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuaracy 86.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY_g96WvT3Yj"
      },
      "source": [
        "## LSTM Model with Dropout on Gates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZeOHlUWTuqK",
        "outputId": "e61d5f91-7455-4646-afa0-c476cdb1d172"
      },
      "source": [
        "np.random.seed(7)\n",
        "\n",
        "top_words = 5000\n",
        "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# Truncate and padding sequence\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test,maxlen=max_review_length)\n",
        "\n",
        "# Create the model\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words,output_dim=embedding_vector_length,input_length=max_review_length))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=90,dropout=0.2,recurrent_dropout=0.2))\n",
        "model.add(Dense(units=1,activation='relu'))\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,batch_size=64,epochs=2,validation_data=(X_test,y_test),verbose=1)\n",
        "\n",
        "# model performace\n",
        "scores = model.evaluate(X_test,y_test,verbose=0)\n",
        "print('Model accuracy: %.2f%%' %(scores[1]*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 500, 32)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 90)                44280     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 91        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 204,371\n",
            "Trainable params: 204,371\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "391/391 [==============================] - 485s 1s/step - loss: 0.6486 - accuracy: 0.6839 - val_loss: 0.5275 - val_accuracy: 0.7600\n",
            "Epoch 2/2\n",
            "391/391 [==============================] - 483s 1s/step - loss: 0.5051 - accuracy: 0.7749 - val_loss: 0.4317 - val_accuracy: 0.8479\n",
            "Model accuracy: 84.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sczYaCJ2YdUS"
      },
      "source": [
        "## LSTM and CNN for sequence classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOH6HOxiWzC6",
        "outputId": "fe9b6a03-07ca-476c-f83a-259369c7864e"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.datasets import imdb\n",
        "np.random.seed(7)\n",
        "\n",
        "top_words = 5000\n",
        "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# Truncate and padding sequence\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test,maxlen=max_review_length)\n",
        "\n",
        "# Create the model\n",
        "embedding_vector_length = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words,output_dim=embedding_vector_length,input_length=max_review_length))\n",
        "\n",
        "model.add(Convolution1D(filters=32,kernel_size=3,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=100,dropout=0.2,recurrent_dropout=0.2))\n",
        "model.add(Dense(units=1,activation='relu'))\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 500, 32)           3104      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 250, 32)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 250, 32)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               53200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 216,405\n",
            "Trainable params: 216,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGIfrGzxao_y",
        "outputId": "64c2f41c-1095-46c6-90e2-e7376f87a843"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,batch_size=64,epochs=2,validation_data=(X_test,y_test),verbose=0)\n",
        "\n",
        "# model performace\n",
        "scores = model.evaluate(X_test,y_test,verbose=0)\n",
        "print('Model accuracy: %.2f%%' %(scores[1]*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 81.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqn8KtHRIKXD"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "1.  Developed a simple single layer LSTM model for the IMDB movie review sentiment classification problem.\n",
        "2.  Extended my LSTM model with layer-wise and LSTM-specific dropout to reduce overfitting.\n",
        "3.  Finally, combined the spatial structure learning properties of a Convolutional Neural Network with the sequence learning of an LSTM. We can increase the model performance by increasing number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY7uXFRIZxO9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}